{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install imutils\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\ishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_notebook_mode, iplot\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvgg16\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16, preprocess_input\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\ishra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "# import pydot\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from colorama import Fore\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from skimage.io import *\n",
    "%config Completer.use_jedi = False\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "print(\"All modules have been imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install tree\n",
    "clear_output()\n",
    "# create new folders\n",
    "!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO\n",
    "!tree -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"../input/brain-tumor-detection-mri/Brain_Tumor_Detection\"\n",
    "\n",
    "# split the data by train/val/test\n",
    "ignored = {\"pred\"}\n",
    "# split the data by train/val/test\n",
    "for CLASS in os.listdir(IMG_PATH):\n",
    "    if CLASS not in ignored:\n",
    "        if not CLASS.startswith(\".\"):\n",
    "            IMG_NUM = len(os.listdir(IMG_PATH + \"/\" + CLASS))\n",
    "            for n, FILE_NAME in enumerate(os.listdir(IMG_PATH + \"/\" + CLASS)):\n",
    "                img = IMG_PATH + \"/\" + CLASS + \"/\" + FILE_NAME\n",
    "                if n < 300:\n",
    "                    shutil.copy(img, \"TEST/\" + CLASS.upper() + \"/\" + FILE_NAME)\n",
    "                elif n < 0.8 * IMG_NUM:\n",
    "                    shutil.copy(img, \"TRAIN/\" + CLASS.upper() + \"/\" + FILE_NAME)\n",
    "                else:\n",
    "                    shutil.copy(img, \"VAL/\" + CLASS.upper() + \"/\" + FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path, img_size=(100, 100)):\n",
    "    \"\"\"\n",
    "    Load resized images as np.arrays to workspace\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    labels = dict()\n",
    "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
    "        if not path.startswith(\".\"):\n",
    "            labels[i] = path\n",
    "            for file in os.listdir(dir_path + path):\n",
    "                if not file.startswith(\".\"):\n",
    "                    img = cv2.imread(dir_path + path + \"/\" + file)\n",
    "                    X.append(img)\n",
    "                    y.append(i)\n",
    "            i += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f\"{len(X)} images loaded from {dir_path} directory.\")\n",
    "    return X, y, labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    cm, classes, normalize=False, title=\"Confusion matrix\", cmap=plt.cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    cm = np.round(cm, 2)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"TRAIN/\"\n",
    "TEST_DIR = \"TEST/\"\n",
    "VAL_DIR = \"VAL/\"\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\n",
    "X_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\n",
    "X_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the number of samples in Training, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dict()\n",
    "y[0] = []\n",
    "y[1] = []\n",
    "for set_name in (y_train, y_val, y_test):\n",
    "    y[0].append(np.sum(set_name == 0))\n",
    "    y[1].append(np.sum(set_name == 1))\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=[\"Train Set\", \"Validation Set\", \"Test Set\"],\n",
    "    y=y[0],\n",
    "    name=\"No\",\n",
    "    marker=dict(color=\"#33cc33\"),\n",
    "    opacity=0.7,\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=[\"Train Set\", \"Validation Set\", \"Test Set\"],\n",
    "    y=y[1],\n",
    "    name=\"Yes\",\n",
    "    marker=dict(color=\"#ff3300\"),\n",
    "    opacity=0.7,\n",
    ")\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title=\"Count of classes in each set\",\n",
    "    xaxis={\"title\": \"Set\"},\n",
    "    yaxis={\"title\": \"Count\"},\n",
    ")\n",
    "fig = go.Figure(data, layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Visualize the images we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(X, y, labels_dict, n=50):\n",
    "    \"\"\"\n",
    "    Creates a gridplot for desired number of images (n) from the specified set\n",
    "    \"\"\"\n",
    "    for index in range(len(labels_dict)):\n",
    "        imgs = X[np.argwhere(y == index)][:n]\n",
    "        j = 10\n",
    "        i = int(n / j)\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        c = 1\n",
    "        for img in imgs:\n",
    "            plt.subplot(i, j, c)\n",
    "            plt.imshow(img[0])\n",
    "\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            c += 1\n",
    "        plt.suptitle(\"Tumor: {}\".format(labels_dict[index]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train, y_train, labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping the images\n",
    "\n",
    "The images we have are of different sizes. But our model accepts images of size (224*224*3) as input. To achienve this ew have to resize the images. Blindly resizing the images can lead to extreme distortions in the images. Hence, We will first crop thie images and then resize them. This will minimize the issue of distortions.\n",
    "\n",
    "This cropping is done by finding contours in the images using the OpenCV Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_imgs(set_name, add_pixels_value=0):\n",
    "    \"\"\"\n",
    "    Finds the extreme points on the image and crops the rectangular out of them\n",
    "    \"\"\"\n",
    "    set_new = []\n",
    "    for img in set_name:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # threshold the image, then perform a series of erosions +\n",
    "        # dilations to remove any small regions of noise\n",
    "        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "        # find contours in thresholded image, then grab the largest one\n",
    "        cnts = cv2.findContours(\n",
    "            thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        # find the extreme points\n",
    "        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "        extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "        extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "        extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "        ADD_PIXELS = add_pixels_value\n",
    "        new_img = img[\n",
    "            extTop[1] - ADD_PIXELS : extBot[1] + ADD_PIXELS,\n",
    "            extLeft[0] - ADD_PIXELS : extRight[0] + ADD_PIXELS,\n",
    "        ].copy()\n",
    "        set_new.append(new_img)\n",
    "\n",
    "    return np.array(set_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "\n",
    "img = cv2.imread(\"./VAL/NO/no852.jpg\")\n",
    "img = cv2.resize(img, dsize=IMG_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# threshold the image, then perform a series of erosions +\n",
    "# dilations to remove any small regions of noise\n",
    "thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "# find contours in thresholded image, then grab the largest one\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# find the extreme points\n",
    "extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "# add contour on the image\n",
    "img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n",
    "\n",
    "# add extreme points\n",
    "img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n",
    "img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n",
    "\n",
    "# crop\n",
    "ADD_PIXELS = 0\n",
    "new_img = img[\n",
    "    extTop[1] - ADD_PIXELS : extBot[1] + ADD_PIXELS,\n",
    "    extLeft[0] - ADD_PIXELS : extRight[0] + ADD_PIXELS,\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize how the cropping works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(141)\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Step 1. Get the original image\")\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_cnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Step 2. Find the biggest contour\")\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_pnt)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Step 3. Find the extreme points\")\n",
    "plt.subplot(144)\n",
    "plt.imshow(new_img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Step 4. Crop the image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_crop = crop_imgs(set_name=X_train)\n",
    "X_val_crop = crop_imgs(set_name=X_val)\n",
    "X_test_crop = crop_imgs(set_name=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the images after being cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train_crop, y_train, labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_images(x_set, y_set, folder_name):\n",
    "    i = 0\n",
    "    for img, imclass in zip(x_set, y_set):\n",
    "        if imclass == 0:\n",
    "            cv2.imwrite(folder_name + \"NO/\" + str(i) + \".jpg\", img)\n",
    "        else:\n",
    "            cv2.imwrite(folder_name + \"YES/\" + str(i) + \".jpg\", img)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving new images to the folder\n",
    "!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO\n",
    "\n",
    "save_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\n",
    "save_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\n",
    "save_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imgs(set_name, img_size):\n",
    "    set_new = []\n",
    "    for img in set_name:\n",
    "        img = cv2.resize(img, dsize=img_size, interpolation=cv2.INTER_CUBIC)\n",
    "        set_new.append(preprocess_input(img))\n",
    "    return np.array(set_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\n",
    "X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\n",
    "X_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(X_train_prep, y_train, labels, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.05,\n",
    "    brightness_range=[0.1, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "os.mkdir(\"preview\")\n",
    "x = X_train_crop[0]\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in demo_datagen.flow(\n",
    "    x, batch_size=1, save_to_dir=\"preview\", save_prefix=\"aug_img\", save_format=\"jpg\"\n",
    "):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "plt.imshow(X_train_crop[0])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "i = 1\n",
    "for img in os.listdir(\"preview/\"):\n",
    "    img = cv2.cv2.imread(\"preview/\" + img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(3, 7, i)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i += 1\n",
    "    if i > 3 * 7:\n",
    "        break\n",
    "plt.suptitle(\"Augemented Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf preview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"TRAIN_CROP/\"\n",
    "VAL_DIR = \"VAL_CROP/\"\n",
    "RANDOM_SEED = 42\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,\n",
    "    class_mode=\"binary\",\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_Neural_Net = VGG19(\n",
    "    input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(base_Neural_Net)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "for layer in base_Neural_Net.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"AUC\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "es = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=6)\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=25,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating with the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train_prep)\n",
    "predictions = [1 if x > 0.5 else 0 for x in predictions]\n",
    "\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(\"Train Accuracy = %.2f\" % accuracy)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_train, predictions)\n",
    "cm = plot_confusion_matrix(confusion_mtx, classes=list(labels.items()), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating with the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val_prep)\n",
    "predictions = [1 if x > 0.5 else 0 for x in predictions]\n",
    "\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(\"Val Accuracy = %.2f\" % accuracy)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_val, predictions)\n",
    "cm = plot_confusion_matrix(confusion_mtx, classes=list(labels.items()), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating with the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate on test set\n",
    "predictions = model.predict(X_test_prep)\n",
    "predictions = [1 if x > 0.5 else 0 for x in predictions]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy = %.2f\" % accuracy)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test, predictions)\n",
    "cm = plot_confusion_matrix(confusion_mtx, classes=list(labels.items()), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pred = model.predict_proba(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the other performance metrics on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy score is :\", metrics.accuracy_score(y_test, predictions))\n",
    "print(\n",
    "    \"Precision score is :\",\n",
    "    metrics.precision_score(y_test, predictions, average=\"weighted\"),\n",
    ")\n",
    "print(\n",
    "    \"Recall score is :\", metrics.recall_score(y_test, predictions, average=\"weighted\")\n",
    ")\n",
    "print(\"F1 Score is :\", metrics.f1_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\n",
    "    \"ROC AUC Score is :\",\n",
    "    metrics.roc_auc_score(y_test, prob_pred, multi_class=\"ovo\", average=\"weighted\"),\n",
    ")\n",
    "print(\"Cohen Kappa Score:\", metrics.cohen_kappa_score(y_test, predictions))\n",
    "print(\n",
    "    \"\\t\\tClassification Report:\\n\", metrics.classification_report(y_test, predictions)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
